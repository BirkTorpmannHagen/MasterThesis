\chapter{Conclusion}\label{conclusion}

% \section{Summary}
% The goal of this work has been to develop novel methods of increasing the generalizability of deep learning models, as well as to further the understanding of the relative impacts of more conventional components of the deep learning pipeline.

% Several methods were proposed to this end, namely DD-DeepLabV3+, Consistency Training, generative polyp inpainting, and the use of ensembles. Among these methods, Consistency Training had the most significant impact and appears to be the most promising with regards to further development. 

% There are a multitude of improvements that could be made for every tested method, and there is much to be gained from more in-depth analysis and experimentation with regards to the relative impacts of all tested methods. 

% Though generalizability remains an open and multifaceted problem, there are evidently multiple promising directions of further study which may yet prove to alleviate generalization failure or at the very least facilitate a deeper understanding of generalizability. In particular, Consistency Training, and in general notion of perturbation consistency, exhibits significant potential towards mitigating generalization failure.
 
\section{Summary}
The goal of this work has been to develop novel methods of increasing the generalizability of deep learning models, as well as to survey the relative impacts of more conventional components of the deep learning pipeline. This was achieved as follows:

\Cref{background} provided an overview of deep learning, segmentation, and delved further into why such systems so readily fail to generalize, starting from first principles and analyzing the shortcomings of \gls{erm}. This was then connected to recent analyses of generalizability failure, including the notion of underspecification and shortcut learning. Finally, known methods of increasing generalization as presented in EndoCV2021 and elsewhere in the literature were then discussed and analyzed with respect to the established theory. 

This was then in turn used to inform the development of the methods discussed in \Cref{methods}, including a novel training paradigm, augmentation technique, model architecture and ensemble models. Each of these methods were also discussed with respect to the theory explored in \Cref{background}.

Several experiments were then conducted in \Cref{experiments} in order to ascertain the impact of the proposed methods:
First, baseline generalizability metric were collected for five separate models. The findings supported the notion that larger models are more prone to generalizability failure, as demonstrated by the significant gap between the Unet and the TriUnet. The use of a secondary decoder in the DD-DeepLabV3+ model was shown to have negligible impact, despite reducing performance variability. It was hypothesized that this is due to the encoder already learning domain- and dataset-independent features. 

In the next experiment, data augmentation was shown to increase generalizability by a considerable margin. Synthetic augmentation via inpainting was shown to hamper this improvement when used in conjunction with regular augmentation, but this finding was deemed inconclusive due to the relatively low performance of the inpainter. 
The impact of consistency training was then tested and compared to regular data augmentation and no augmentation. The results show that consistency training outperforms regular data augmentation by a considerable margin on the most difficult of the three \gls{ood} datasets. 

Finally, predictors trained according to the best methods as identified in the previous experiments were then combined into ensembles. The results demonstrated the generalizability of ensemble-based methods, but further analysis did not sufficiently corroborate that this improvement can be attributed to ensembles mitigating underspecification. 

The results from this experiment was then discussed in \Cref{discussion}. Limitations of the experiments were noted, along with their practical impacts and possible directions of further study and potential ways to improve the methods proposed in this thesis. 


\section{Contributions}
The main contributions in this thesis can be regarded as twofold:

First, the thesis introduces a new way of thinking about generalization as consistency to perturbations. This informed the development of Consistency Training, which was shown to increase generalizability by a greater margin than all other tested methods, including data augmentation. This framework, and the potential improvements that can be made upon it as suggested in \Cref{discussion}, shows good promise with regards to further increasing generalizability. 

Second, this work provides an exploratory overview of how generalizability is affected by the choice of model architecture, augmentation strategy, and the use of ensembles. Though most of the findings corroborated the literature, there were a fair number of surprising results that warrant further investigation, in particular with regards to the impacts of the tested methods relative to one another. For one, the effect of multitask learning and generally the the choice of model architecture was practically negligible. With the exception of TriUnet, every tested model exhibited practically identical performance. Ensembles, though exhibiting statistically significant impact, resulted in somewhat marginal improvements on generalization, especially in comparison to the use of data augmentation and consistency training. As discussed in \Cref{discussion}, this raises doubts as to the veracity of findings in other literature, where data augmentation is rarely accounted for when performing comparisons. Hopefully, the findings in this thesis demonstrates the need for a more structured approach to the design of experimental methodologies intended to analyze generalization, wherein the constituent components of the pipeline are sufficiently controlled. 

\section{Future Work}
There are a myriad of promising directions for further work. These are detailed in \Cref{discussion} and can be summarized as follows:

There are several ways to improve Consistency Training. One may for instance modify the segmentation inconsistency loss as outlined in \Cref{new_closs}. It is also possible to incorporate the notion of consistency in more advanced pipelines, such as through denoising networks as outlined in \Cref{denoising}. Adversarial sampling of perturbations or otherwise modifying the perturbation model may also have merit.  

Further investigating the effect of multiple-decoder models may also prove insightful, in particular as a countermeasure to underspecification. Analyzing the latent representations and the differences that these decoders induce may also provide a better understanding of what the encoders actually learn, and corroborate the hypothesis made in \Cref{models} that they learn dataset- and thus task-invariant features. 

Repeating the experiments performed in this thesis without pretraining may also be interesting. There may for instance be a relationship between pretraining and the aforementioned tendency of encoders to learn task-independent features which such experiments would highlight.  

As this thesis merely explored the impacts of model architectures, data augmentation and ensemble models on a surface level, there is naturally space for more in-depth exploration of the relationships suggested by the findings in \Cref{experiments}. In particular, a more in-depth analysis of the impact of data augmentation is warranted, in particular in regards to the relative impacts thereof in comparison to other methods. A meta-analysis of the findings in EndoCV2021 wherein the same augmentation method is kept across all submitted methods may for instance be a useful point of further study towards developing more robust experimental methods to evaluate generalization. 